{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Any, Set, Callable, Hashable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "  # 'rec_id',\n",
    "  'given_name',\n",
    "  'surname',\n",
    "  'street_number',\n",
    "  'address_1',\n",
    "  'address_2',\n",
    "  'suburb',\n",
    "  # 'postcode',\n",
    "  'state',\n",
    "  'date_of_birth',\n",
    "  # 'age',\n",
    "  'phone_number',\n",
    "  # 'soc_sec_id',\n",
    "  # 'blocking_number'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_address(address: str) -> str:\n",
    "    # Список слов и сокращений для удаления\n",
    "    words_to_remove = [\n",
    "        \"улица\", \"ул\\\\. ?\", \"проспект\", \"пр-т\\\\. ?\", \"пр\\\\. ?\", \"бульвар\", \"б-р\\\\. ?\", \"переулок\", \"пер\\\\. ?\", \"набережная\", \"наб\\\\. ?\",\n",
    "        \"шоссе\", \"площадь\", \"пл\\\\. ?\", \"дом\", \"д\\\\. ?\", \"квартира\", \"кв\\\\. ?\", \"корпус\", \"корп\\\\. ?\", \"строение\", \"стр\\\\. ?\", \"область\",\n",
    "        \"обл\\\\. ?\", \"город\", \"г\\\\. ?\", \"поселок\", \"пос\\\\. ?\", \"деревня\", \"дер\\\\. ?\",\n",
    "        \"street\", \"st\\\\. ?\", \"avenue\", \"ave\\\\. ?\", \"boulevard\", \"blvd\\\\. ?\", \"alley\", \"al\\\\. ?\", \"drive\", \"dr\\\\. ?\",\n",
    "        \"square\", \"sq\\\\. ?\", \"house\", \"h\\\\. ?\", \"apartment\", \"apt\\\\. ?\", \"building\", \"bldg\\\\. ?\", \"county\", \"co\\\\. ?\",\n",
    "        \"city\", \"ct\\\\. ?\", \"village\", \"vil\\\\. ?\", \"township\", \"twp\\\\. ?\", \"road\", \"rd\\\\. ?\"\n",
    "    ]\n",
    "\n",
    "    # Создаем регулярное выражение из списка слов и сокращений\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(words_to_remove))\n",
    "\n",
    "    # Заменяем найденные слова и сокращения на пустую строку\n",
    "    cleaned_address = re.sub(pattern, '', address, flags=re.IGNORECASE)\n",
    "\n",
    "    # Удаляем лишние пробелы и возвращаем очищенную строку\n",
    "    return re.sub(r'\\s+', ' ', cleaned_address).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(x: str) -> str:\n",
    "    # Формируем ключ из значений полей\n",
    "    return  '-'.join([x.split('-')[0], x.split('-')[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('test.csv', dtype=str)\n",
    "data = data.applymap(lambda x:  x.strip() if isinstance(x, str) else x )\n",
    "# data['address_1'] = data['address_1'].apply(lambda x:  clean_address(x) if isinstance(x, str) else x )\n",
    "# data['address_2'] = data['address_2'].apply(lambda x:  clean_address(x) if isinstance(x, str) else x )\n",
    "# data = data.applymap(lambda x:  clean_address(x) if isinstance(x, str) else x )\n",
    "data = data.replace({np.nan:None})\n",
    "data['rec_common_id'] = data.apply(lambda x: get_key(x['rec_id']), axis=1)\n",
    "data_list = data.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_ids = {}\n",
    "expected_res = {}\n",
    "origs = {}\n",
    "for record in data_list:\n",
    "    if record['rec_common_id'] not in data_by_ids:\n",
    "        data_by_ids[record['rec_common_id']] = []\n",
    "        expected_res[record['rec_common_id']] = set()\n",
    "    data_by_ids[record['rec_common_id']].append(record)\n",
    "    expected_res[record['rec_common_id']].add(record['rec_id'])\n",
    "    if 'org' in record['rec_id']:\n",
    "        origs[record['rec_id']] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distances.levenshtein import levenstein_similarity, levenshtein_distance_memopt\n",
    "from distances.jaro import jaro_winkler_similarity\n",
    "from distances.damerau_levenstein import damerau_levenshtein_similarity, damerau_levenshtein_distance_memopt\n",
    "from distances.jaccard import jaccard_similarity_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_mean(a: Dict[Hashable, Any], b: Dict[Hashable, Any], sim: Callable[[str, str], float]) -> float:\n",
    "  sm = 0\n",
    "  cnt = 0\n",
    "  for k in column_names:\n",
    "    if a[k] is not None and b[k] is not None and isinstance(a[k], str) and a[k] != '' and isinstance(b[k], str) and b[k] != '':\n",
    "      sm += sim(a[k], b[k])\n",
    "      cnt += 1\n",
    "  if cnt == 0:\n",
    "    return 0\n",
    "  return sm / cnt\n",
    "def get_lev_sim(a: Dict[Hashable, Any], b: Dict[Hashable, Any]) -> float:\n",
    "  return get_sim_mean(a, b, levenstein_similarity)\n",
    "def get_dam_lev_sim(a: Dict[Hashable, Any], b: Dict[Hashable, Any]) -> float:\n",
    "  return get_sim_mean(a, b, damerau_levenshtein_similarity)\n",
    "def get_jaro_sim(a: Dict[Hashable, Any], b: Dict[Hashable, Any]) -> float:\n",
    "  return get_sim_mean(a, b, jaro_winkler_similarity)\n",
    "def get_jaccard_sim(a: Dict[Hashable, Any], b: Dict[Hashable, Any]) -> float:\n",
    "  return get_sim_mean(a, b, jaccard_similarity_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = data_by_ids['rec-148']\n",
    "# main_rec = test_data[-1]\n",
    "# test_data = test_data[:-1]\n",
    "# test_data.append(data_by_ids['rec-100'][0])\n",
    "# for td in test_data:\n",
    "#   sim = get_lev_sim(main_rec, td)\n",
    "#   print(f'main_rec_id: {main_rec[\"rec_id\"]}, td_rec_id: {td[\"rec_id\"]}, similarity: {sim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in column_names:\n",
    "#   if main_rec[k] is not None and isinstance(main_rec[k], str):\n",
    "#     print(f'{k}: {main_rec[k]}')\n",
    "# for k in column_names:\n",
    "#   if test_data[2][k] is not None and isinstance(test_data[2][k], str):\n",
    "#     print(f'{k}: {test_data[2][k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_distances(data: List[Dict[Hashable, Any]], expected_res: Dict[str, Set[str]], similarity: Callable[[Dict[Hashable, Any], Dict[Hashable, Any]], float],threshold: float = 0.85) -> Tuple[int, int, int]:\n",
    "  tp = 0\n",
    "  fp = 0\n",
    "  fn = 0\n",
    "  res = []\n",
    "  for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "      sim = similarity(data[i], data[j])\n",
    "      if sim > threshold:\n",
    "        res.append((data[i]['rec_id'], data[j]['rec_id'], sim))\n",
    "  res_by_ids = {}\n",
    "  for (a_id, b_id, sim) in res:\n",
    "    a_key = get_key(a_id)\n",
    "    b_key = get_key(b_id)\n",
    "    if a_key != b_key:\n",
    "      print(f'ERROR: {a_id}, {b_id}, {sim}')\n",
    "      fp += 1\n",
    "      continue\n",
    "    if a_key not in res_by_ids:\n",
    "      res_by_ids[a_key] = set()\n",
    "    res_by_ids[a_key].add(a_id)\n",
    "    res_by_ids[a_key].add(b_id)\n",
    "  for key in expected_res:\n",
    "    if key not in res_by_ids:\n",
    "      if len(expected_res[key]) > 1:\n",
    "        # print(f'ERROR: not found {key}')\n",
    "        fn += len(expected_res[key])\n",
    "      continue\n",
    "    # if len(expected_res[key]) != len(res_by_ids[key]):\n",
    "    #   print(f'ERROR: not full {key}')\n",
    "    fn += len(expected_res[key]) - len(res_by_ids[key])\n",
    "    tp += len(res_by_ids[key])\n",
    "  return tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEVENSTEIN\n",
      "tp: 452, fp: 0, fn: 85\n",
      "precision: 1.0\n",
      "recall: 0.8417132216014898\n",
      "f1: 0.9140546006066734\n"
     ]
    }
   ],
   "source": [
    "(tp, fp, fn) = test_distances(data_list, expected_res, get_lev_sim)\n",
    "print('LEVENSTEIN')\n",
    "print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {2 * precision * recall / (precision + recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JARO\n",
      "tp: 473, fp: 0, fn: 64\n",
      "precision: 1.0\n",
      "recall: 0.8808193668528864\n",
      "f1: 0.9366336633663366\n"
     ]
    }
   ],
   "source": [
    "(tp, fp, fn) = test_distances(data_list, expected_res, get_jaro_sim)\n",
    "print('JARO')\n",
    "print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {2 * precision * recall / (precision + recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAMERAU LEVENSTEIN\n",
      "tp: 459, fp: 0, fn: 78\n",
      "precision: 1.0\n",
      "recall: 0.8547486033519553\n",
      "f1: 0.9216867469879518\n"
     ]
    }
   ],
   "source": [
    "(tp, fp, fn) = test_distances(data_list, expected_res, get_dam_lev_sim)\n",
    "print('DAMERAU LEVENSTEIN')\n",
    "print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {2 * precision * recall / (precision + recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JACCARD\n",
      "tp: 460, fp: 0, fn: 77\n",
      "precision: 1.0\n",
      "recall: 0.8566108007448789\n",
      "f1: 0.9227683049147443\n"
     ]
    }
   ],
   "source": [
    "(tp, fp, fn) = test_distances(data_list, expected_res, get_jaccard_sim)\n",
    "print('JACCARD')\n",
    "print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'f1: {2 * precision * recall / (precision + recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dcs import dcs_plus_plus\n",
    "from dm_soundex import encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcs_key(r: Dict[Hashable, Any]) -> str:\n",
    "  name = r['given_name']\n",
    "  sur = r['surname']\n",
    "  if name is None:\n",
    "    name = ''\n",
    "  # elif name != '':\n",
    "  #   name = encode(name, max_length=10, zero_pad=True)\n",
    "  if sur is None:\n",
    "    sur = ''\n",
    "  # elif sur != '':\n",
    "  #   sur = encode(sur, max_length=10, zero_pad=True)\n",
    "  s = f'{name}{sur}'\n",
    "  if s == '':\n",
    "    return '0'*10\n",
    "  # print(encode(r['surname'], max_length=10, zero_pad=True))\n",
    "  return s\n",
    "def is_duplicate(r1: Dict[Hashable, Any], r2: Dict[Hashable, Any]) -> bool:\n",
    "  return get_jaccard_sim(r1, r2) > 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_stats(res: List[Tuple[Dict[Hashable, Any], Dict[Hashable, Any]]], expected_res) -> None:\n",
    "  tp = 0\n",
    "  fp = 0\n",
    "  fn = 0\n",
    "  res_by_ids = {}\n",
    "  for (a, b) in res:\n",
    "    a_id = a['rec_id']\n",
    "    b_id = b['rec_id']\n",
    "    if a_id == b_id:\n",
    "      # print(f'ERROR: {a_id}, {b_id}')\n",
    "      continue\n",
    "    a_key = get_key(a_id)\n",
    "    b_key = get_key(b_id)\n",
    "    if a_key != b_key:\n",
    "      # print(f'ERROR: {a_id}, {b_id}, {sim}')\n",
    "      fp += 1\n",
    "      continue\n",
    "    if a_key not in res_by_ids:\n",
    "      res_by_ids[a_key] = set()\n",
    "    res_by_ids[a_key].add(a_id)\n",
    "    res_by_ids[a_key].add(b_id)\n",
    "  for key in expected_res:\n",
    "    if key not in res_by_ids:\n",
    "      if len(expected_res[key]) > 1:\n",
    "        # print(f'ERROR: not found {key}')\n",
    "        fn += len(expected_res[key])\n",
    "      continue\n",
    "    # if len(expected_res[key]) != len(res_by_ids[key]):\n",
    "    #   print(f'ERROR: not full {key}')\n",
    "    fn += len(expected_res[key]) - len(res_by_ids[key])\n",
    "    tp += len(res_by_ids[key])\n",
    "  print(f'tp: {tp}, fp: {fp}, fn: {fn}')\n",
    "  precision = tp / (tp + fp)\n",
    "  recall = tp / (tp + fn)\n",
    "  print(f'precision: {precision}')\n",
    "  print(f'recall: {recall}')\n",
    "  print(f'f1: {2 * precision * recall / (precision + recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dcs_plus_plus(data_list, dcs_key, is_duplicate=is_duplicate, w=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 413, fp: 0, fn: 124\n",
      "precision: 1.0\n",
      "recall: 0.7690875232774674\n",
      "f1: 0.8694736842105263\n"
     ]
    }
   ],
   "source": [
    "res_stats(res, expected_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lev_dist(a: Dict[Hashable, Any], b: Dict[Hashable, Any]) -> int:\n",
    "  a_s = ''\n",
    "  b_s = ''\n",
    "  for k in column_names:\n",
    "    if a[k] is not None and isinstance(a[k], str) and a[k] != '' and b[k] is not None and isinstance(b[k], str) and b[k] != '':\n",
    "      a_s += a[k]\n",
    "      b_s += b[k]\n",
    "  return damerau_levenshtein_distance_memopt(a_s, b_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bk_tree import BKTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkt = BKTree(get_lev_dist)\n",
    "for r in data_list:\n",
    "  bkt.insert(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res: List[Tuple[Dict[Hashable, Any], Dict[Hashable, Any]]] = []\n",
    "qres = []\n",
    "for org in origs.values():\n",
    "  q_res = bkt.query(org, 15)\n",
    "  for (_,r) in q_res:\n",
    "    if r['rec_id'] != org['rec_id']:\n",
    "      res.append((org, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 524, fp: 35, fn: 13\n",
      "precision: 0.9373881932021467\n",
      "recall: 0.9757914338919925\n",
      "f1: 0.9562043795620438\n"
     ]
    }
   ],
   "source": [
    "res_stats(res, expected_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bk2 import BKTree as BK2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk2 = BK2(get_lev_dist)\n",
    "for r in data_list:\n",
    "  bk2.insert(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res: List[Tuple[Dict[Hashable, Any], Dict[Hashable, Any]]] = []\n",
    "for org in origs.values():\n",
    "  q_res = bkt.query(org, 15)\n",
    "  for (_,r) in q_res:\n",
    "    if r['rec_id'] != org['rec_id']:\n",
    "      res.append((org, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 524, fp: 35, fn: 13\n",
      "precision: 0.9373881932021467\n",
      "recall: 0.9757914338919925\n",
      "f1: 0.9562043795620438\n"
     ]
    }
   ],
   "source": [
    "res_stats(res, expected_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
